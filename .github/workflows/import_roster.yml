name: Import Roster Site (WO/Export)

on:
  workflow_dispatch: {}
  schedule:
    # Runs frequently to approximate "instant" updates from Power Automate email flow.
    - cron: "*/5 * * * *"

permissions:
  contents: write

jobs:
  build_import:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # NOTE: We detect changes by hashing the downloaded XLSX bytes from SharePoint.
      # This keeps Import isolated and does NOT touch Export (no EXCEL_URL / no last_filename.txt).
      - name: Check if Import Excel file changed
        id: check_import_changes
        env:
          IMPORT_EXCEL_URL: ${{ secrets.IMPORT_EXCEL_URL }}
        run: |
          python << 'EOF'
          import os, sys, hashlib
          from pathlib import Path
          import requests

          def main():
              url = os.getenv("IMPORT_EXCEL_URL")
              if not url:
                  print("IMPORT_EXCEL_URL secret is missing")
                  sys.exit(1)

              # Download Excel
              r = requests.get(url, timeout=60)
              r.raise_for_status()
              data = r.content

              # Basic sanity check: XLSX is a zip starting with PK
              if not data.startswith(b"PK"):
                  print("Downloaded content does not look like an XLSX (missing PK header).")
                  print("First bytes:", data[:16])
                  sys.exit(1)

              h = hashlib.sha256(data).hexdigest()
              cache_file = Path("import_last_hash.txt")
              old = cache_file.read_text(encoding="utf-8").strip() if cache_file.exists() else ""
              changed = (h != old)

              cache_file.write_text(h, encoding="utf-8")

              out = os.environ["GITHUB_OUTPUT"]
              with open(out, "a", encoding="utf-8") as f:
                  f.write(f"changed={str(changed).lower()}\n")
                  f.write(f"hash={h}\n")
                  f.write(f"old_hash={old}\n")

              print("========================================")
              print("Import Excel hash:", h)
              print("Previous hash   :", old or "(none)")
              print("Changed         :", changed)
              print("========================================")

          if __name__ == "__main__":
              main()
          EOF

      - name: Generate Import pages
        if: steps.check_import_changes.outputs.changed == 'true'
        env:
          IMPORT_EXCEL_URL: ${{ secrets.IMPORT_EXCEL_URL }}
          PAGES_BASE_URL: ${{ secrets.PAGES_BASE_URL }}
          # Optional display metadata (you can set later if you want)
          IMPORT_ORIGINAL_FILENAME: ""
          IMPORT_RECEIVED_AT: ""
        run: |
          echo "Import file changed â†’ generating /docs/import ..."
          python generate_and_send_import.py
          echo "Done!"

      - name: Commit updated Import docs
        if: steps.check_import_changes.outputs.changed == 'true'
        run: |
          git config user.name "github-actions"
          git config user.email "github-actions@github.com"
          git add docs/import import_last_hash.txt
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Update IMPORT roster"
            git push
            echo "Pushed!"
          fi

      - name: Skip - No Import changes
        if: steps.check_import_changes.outputs.changed == 'false'
        run: |
          echo "No Import change detected (hash unchanged)."
